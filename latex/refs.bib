@book{chen2006nuhanzi,
  title        = {{女漢字典} [Nu Han Zi Dian: Nüshu Chinese Character Dictionary]},
  author       = {Qi Guang Chen},
  publisher    = {{中央民族大學出版社} [Central University for Nationalities Press]},
  year         = {2006},
  isbn         = {7810569864, 9787810569866},
  pages        = {760},
  language     = {zh},
  note         = {This dictionary compiles over 3400 characters from original manuscripts, copies, and rubbings of Nüshu texts. It annotates the form, pronunciation, and meaning of each character, and documents their evolution into standard Chinese characters.}
}
@book{zhao2005nushu,
  title        = {{中國女書合集（全五冊）} [Collected Works of Chinese Nüshu (5 volumes)]},
  author       = {Liming Zhao},
  publisher    = {{中華書局} [Zhonghua Book Company]},
  year         = {2005},
  isbn         = {9787101044058},
  pages        = {4406},
  language     = {zh},
  note         = {This is the most comprehensive compilation of Nüshu texts, the world's only known women-only script, including over 652 manuscripts with scanned facsimiles, translations, and annotations. The collection covers more than 90\% of all extant Nüshu materials and provides valuable resources for linguistics, philology, literature, anthropology, folklore, and sociology.},
  series       = {5 volumes}
}
@book{zhang2006nushu,
  title        = {{女書用字比較} [A Comparative Study of Nüshu Characters]},
  author       = {Xiurong Zhang and Kun Guo and Jingquan He},
  contributor  = {Liming Zhao},
  publisher    = {{知識產權出版社} [Intellectual Property Publishing House]},
  year         = {2006},
  isbn         = {7801982614, 9787801982612},
  pages        = {256},
  language     = {zh},
  note         = {This book provides a comparative study of Nüshu characters, including analyses of the social and cultural foundations of Chinese Marxism, its theoretical achievements, and innovations.}
}
@article{huLoRALowRankAdaptation2021,
  title = {{{LoRA}}: {{Low-Rank Adaptation}} of {{Large Language Models}}},
  shorttitle = {{{LoRA}}},
  author = {Hu, J. E. and Shen, Yelong and Wallis, Phillip and {Allen-Zhu}, Zeyuan and Li, Yuanzhi and Wang, Shean and Chen, Weizhu},
  year = {2021},
  month = jun,
  journal = {ArXiv},
  urldate = {2025-05-12},
  abstract = {An important paradigm of natural language processing consists of large-scale pre-training on general domain data and adaptation to particular tasks or domains. As we pre-train larger models, full fine-tuning, which retrains all model parameters, becomes less feasible. Using GPT-3 175B as an example -- deploying independent instances of fine-tuned models, each with 175B parameters, is prohibitively expensive. We propose Low-Rank Adaptation, or LoRA, which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks. Compared to GPT-3 175B fine-tuned with Adam, LoRA can reduce the number of trainable parameters by 10,000 times and the GPU memory requirement by 3 times. LoRA performs on-par or better than fine-tuning in model quality on RoBERTa, DeBERTa, GPT-2, and GPT-3, despite having fewer trainable parameters, a higher training throughput, and, unlike adapters, no additional inference latency. We also provide an empirical investigation into rank-deficiency in language model adaptation, which sheds light on the efficacy of LoRA. We release a package that facilitates the integration of LoRA with PyTorch models and provide our implementations and model checkpoints for RoBERTa, DeBERTa, and GPT-2 at https://github.com/microsoft/LoRA.},
  langid = {english},
  file = {F:\Zotero File\storage\VI5CJVKR\Hu 等 - 2021 - LoRA Low-Rank Adaptation of Large Language Models.pdf}
}
@article{hoganKnowledgeGraphs2022,
  title = {Knowledge {{Graphs}}},
  author = {Hogan, Aidan and Blomqvist, Eva and Cochez, Michael and D'amato, Claudia and Melo, Gerard De and Gutierrez, Claudio and Kirrane, Sabrina and Gayo, Jos{\'e} Emilio Labra and Navigli, Roberto and Neumaier, Sebastian and Ngomo, Axel-Cyrille Ngonga and Polleres, Axel and Rashid, Sabbir M. and Rula, Anisa and Schmelzeisen, Lukas and Sequeda, Juan and Staab, Steffen and Zimmermann, Antoine},
  year = {2022},
  month = may,
  journal = {ACM Computing Surveys},
  volume = {54},
  number = {4},
  pages = {1--37},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/3447772},
  urldate = {2025-05-12},
  abstract = {In this article, we provide a comprehensive introduction to knowledge graphs, which have recently garnered significant attention from both industry and academia in scenarios that require exploiting diverse, dynamic, large-scale collections of data. After some opening remarks, we motivate and contrast various graph-based data models, as well as languages used to query and validate knowledge graphs. We explain how knowledge can be represented and extracted using a combination of deductive and inductive techniques. We conclude with high-level future research directions for knowledge graphs.},
  langid = {english},
  file = {F:\Zotero File\storage\8FG7PRQ9\Hogan 等 - 2022 - Knowledge Graphs.pdf}
}
@misc{gaoRetrievalAugmentedGenerationLarge2024,
  title = {Retrieval-{{Augmented Generation}} for {{Large Language Models}}: {{A Survey}}},
  shorttitle = {Retrieval-{{Augmented Generation}} for {{Large Language Models}}},
  author = {Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yi and Sun, Jiawei and Wang, Meng and Wang, Haofen},
  year = {2024},
  month = mar,
  number = {arXiv:2312.10997},
  eprint = {2312.10997},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2312.10997},
  urldate = {2025-05-12},
  abstract = {Large Language Models (LLMs) showcase impressive capabilities but encounter challenges like hallucination, outdated knowledge, and non-transparent, untraceable reasoning processes. Retrieval-Augmented Generation (RAG) has emerged as a promising solution by incorporating knowledge from external databases. This enhances the accuracy and credibility of the generation, particularly for knowledge-intensive tasks, and allows for continuous knowledge updates and integration of domain-specific information. RAG synergistically merges LLMs' intrinsic knowledge with the vast, dynamic repositories of external databases. This comprehensive review paper offers a detailed examination of the progression of RAG paradigms, encompassing the Naive RAG, the Advanced RAG, and the Modular RAG. It meticulously scrutinizes the tripartite foundation of RAG frameworks, which includes the retrieval, the generation and the augmentation techniques. The paper highlights the state-of-the-art technologies embedded in each of these critical components, providing a profound understanding of the advancements in RAG systems. Furthermore, this paper introduces up-to-date evaluation framework and benchmark. At the end, this article delineates the challenges currently faced and points out prospective avenues for research and development.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {F\:\\Zotero File\\storage\\HQH5P36V\\Gao 等 - 2024 - Retrieval-Augmented Generation for Large Language Models A Survey.pdf;F\:\\Zotero File\\storage\\5MFJPS79\\2312.html}
}
@article{deepseek-aiDeepSeekR1IncentivizingReasoning2025,
  title = {{{DeepSeek-R1}}: {{Incentivizing Reasoning Capability}} in {{LLMs}} via {{Reinforcement Learning}}},
  shorttitle = {{{DeepSeek-R1}}},
  author = {{DeepSeek-AI} and Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and Zhang, Xiaokang and Yu, Xingkai and Wu, Yu and Wu, Z. F. and Gou, Zhibin and Shao, Zhihong and Li, Zhuoshu and Gao, Ziyi and Liu, Aixin and Xue, Bing and Wang, Bingxuan and Wu, Bochao and Feng, Bei and Lu, Chengda and Zhao, Chenggang and Deng, Chengqi and Zhang, Chenyu and Ruan, Chong and Dai, Damai and Chen, Deli and Ji, Dongjie and Li, Erhang and Lin, Fangyun and Dai, Fucong and Luo, Fuli and Hao, Guangbo and Chen, Guanting and Li, Guowei and Zhang, H. and Bao, Han and Xu, Hanwei and Wang, Haocheng and Ding, Honghui and Xin, Huajian and Gao, Huazuo and Qu, Hui and Li, Hui and Guo, Jianzhong and Li, Jiashi and Wang, Jiawei and Chen, Jingchang and Yuan, Jingyang and Qiu, Junjie and Li, Junlong and Cai, J. L. and Ni, Jiaqi and Liang, Jian and Chen, Jin and Dong, Kai and Hu, Kai and Gao, Kaige and Guan, Kang and Huang, Kexin and Yu, Kuai and Wang, Lean and Zhang, Lecong and Zhao, Liang and Wang, Litong and Zhang, Liyue and Xu, Lei and Xia, Leyi and Zhang, Mingchuan and Zhang, Minghua and Tang, Minghui and Li, Meng and Wang, Miaojun and Li, Mingming and Tian, Ning and Huang, Panpan and Zhang, Peng and Wang, Qiancheng and Chen, Qinyu and Du, Qiushi and Ge, Ruiqi and Zhang, Ruisong and Pan, Ruizhe and Wang, Runji and Chen, R. J. and Jin, R. L. and Chen, Ruyi and Lu, Shanghao and Zhou, Shangyan and Chen, Shanhuang and Ye, Shengfeng and Wang, Shiyu and Yu, Shuiping and Zhou, Shunfeng and Pan, Shuting and Li, S. S. and Zhou, Shuang and Wu, Shaoqing and Yun, Tao and Pei, Tian and Sun, Tianyu and Wang, T. and Zeng, Wangding and Zhao, Wanjia and Liu, Wen and Liang, Wenfeng and Gao, Wenjun and Yu, Wenqin and Zhang, Wentao and Xiao, W. L. and An, Wei and Liu, Xiaodong and Wang, Xiaohan and Chen, Xiaokang and Nie, Xiaotao and Cheng, Xin and Liu, Xin and Xie, Xin and Liu, Xingchao and Yang, Xinyu and Li, Xinyuan and Su, Xuecheng and Lin, Xuheng and Li, X. Q. and Jin, Xiangyue and Shen, Xiaojin and Chen, Xiaosha and Sun, Xiaowen and Wang, Xiaoxiang and Song, Xinnan and Zhou, Xinyi and Wang, Xianzu and Shan, Xinxia and Li, Y. K. and Wang, Y. Q. and Wei, Y. X. and Zhang, Yang and Xu, Yanhong and Li, Yao and Zhao, Yao and Sun, Yaofeng and Wang, Yaohui and Yu, Yi and Zhang, Yichao and Shi, Yifan and Xiong, Yiliang and He, Ying and Piao, Yishi and Wang, Yisong and Tan, Yixuan and Ma, Yiyang and Liu, Yiyuan and Guo, Yongqiang and Ou, Yuan and Wang, Yuduan and Gong, Yue and Zou, Yuheng and He, Yujia and Xiong, Yunfan and Luo, Yuxiang and You, Yuxiang and Liu, Yuxuan and Zhou, Yuyang and Zhu, Y. X. and Huang, Yanping and Li, Yaohui and Zheng, Yi and Zhu, Yuchen and Ma, Yunxian and Tang, Ying and Zha, Yukun and Yan, Yuting and Ren, Z. Z. and Ren, Zehui and Sha, Zhangli and Fu, Zhe and Xu, Zhean and Xie, Zhenda and Zhang, Zhengyan and Hao, Zhewen and Ma, Zhicheng and Yan, Zhigang and Wu, Zhiyu and Gu, Zihui and Zhu, Zijia and Liu, Zijun and Li, Zilin and Xie, Ziwei and Song, Ziyang and Pan, Zizheng and Huang, Zhen and Xu, Zhipeng and Zhang, Zhongyu and Zhang, Zhen},
  year = {2025},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2501.12948},
  urldate = {2025-05-12},
  abstract = {We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities. Through RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing reasoning behaviors. However, it encounters challenges such as poor readability, and language mixing. To address these issues and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeek-R1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {Artificial Intelligence (cs.AI),Computation and Language (cs.CL),FOS: Computer and information sciences,Machine Learning (cs.LG)},
  file = {F:\Zotero File\storage\VB3GDYZ2\DeepSeek-AI 等 - 2025 - DeepSeek-R1 Incentivizing Reasoning Capability in LLMs via Reinforcement Learning.pdf}
}
@inproceedings{mitricAIComputerVision2024,
  title = {{{AI}} and {{Computer Vision}} in {{Cultural Heritage Preservation}}},
  booktitle = {2024 28th {{International Conference}} on {{Information Technology}} ({{IT}})},
  author = {Mitric, Jovana and Radulovic, Igor and Popovic, Tomo and Scekic, Zoja and Tinaj, Sandra},
  year = {2024},
  month = feb,
  pages = {1--4},
  issn = {2836-3744},
  doi = {10.1109/IT61232.2024.10475738},
  urldate = {2025-05-12},
  abstract = {In the recent years, rapid advances in technology, especially in Artificial Intelligence (AI) and Machine Learning (ML), have impacted the way economy functions, as well as society at large. The integration of these technologies in tourism plays a significant role in cultural heritage preservation. This research explores the intersection of artificial intelligence, cultural heritage, and tourism, with a focus on Montenegro's efforts to leverage digital transformation for tourism development. Many monuments are not marked and there is no background information about their historical significance. With four UNESCO World Heritage sites, Montenegro is recognized as country with high touristic potential and rich cultural heritage, which implies that implementation of AI technologies can preserve forgotten monuments and give them a new life, as well as enhance the overall touristic experience and position Montenegro at the forefront of international touristic landscape. Using a well-known framework Flask, we developed web application that allows users to take images of a monument, upload it to our web application and after a few seconds, they get annotated image of a recognized monument, along with a text containing more information about the said monument.},
  keywords = {artificial intelligence,Computational modeling,computer vision,Computer vision,cultural heritage preservation,Digital transformation,Learning (artificial intelligence),machine learning,Machine learning,Mobile applications,Text recognition},
  file = {F:\Zotero File\storage\3966JI4B\Mitric 等 - 2024 - AI and Computer Vision in Cultural Heritage Preservation.pdf}
}
@article{harisantyCulturalHeritagePreservation2024,
  title = {Cultural Heritage Preservation in the Digital Age, Harnessing Artificial Intelligence for the Future: A Bibliometric Analysis},
  shorttitle = {Cultural Heritage Preservation in the Digital Age, Harnessing Artificial Intelligence for the Future},
  author = {Harisanty, Dessy and Obille, Kathleen Lourdes Ballesteros and Anna, Nove E. Variant and Purwanti, Endah and Retrialisca, Fitri},
  year = {2024},
  month = sep,
  journal = {Digital Library Perspectives},
  volume = {40},
  number = {4},
  pages = {609--630},
  publisher = {Emerald Publishing Limited},
  issn = {2059-5816},
  doi = {10.1108/DLP-01-2024-0018},
  urldate = {2025-05-12},
  abstract = {This study aims to investigate the performance analysis, science mapping and future direction of artificial intelligence (AI) technology, applications, tools and software used to preserve, curate and predict the historical value of cultural heritage.,This study uses the bibliometric research method and utilizes the Scopus database to gather data. The keywords used are ``artificial intelligence'' and ``cultural heritage,'' resulting in 718 data sets spanning from 2001 to 2023. The data is restricted to the years 2001-2023, is in English language and encompasses all types of documents, including conference papers, articles, book chapters, lecture notes, reviews and editorials.,The performance analysis of research on the use of AI to aid in the preservation of cultural heritage has been ongoing since 2001, and research in this area continues to grow. The countries contributing to this research include Italy, China, Greece, Spain and the UK, with Italy being the most prolific in terms of authored works. The research primarily falls under the disciplines of computer science, mathematics, engineering, social sciences and arts and humanities, respectively. Document types mainly consist of articles and proceedings. In the science mapping process, five clusters have been identified. These clusters are labeled according to the contributions of AI tools, software, apps and technology to cultural heritage preservation. The clusters include ``conservation assessment,'' ``exhibition and visualization,'' ``software solutions,'' ``virtual exhibition'' and ``metadata and database.'' The future direction of research lies in extended reality, which integrates virtual reality (VR), augmented reality (AR) and mixed reality (MR); virtual restoration and preservation; 3D printing; as well as the utilization of robotics, drones and the Internet of Things (IoT) for mapping, conserving and monitoring historical sites and cultural heritage sites.,The cultural heritage institution can use this result as a source to develop AI-based strategic planning for curating, preservation, preventing and presenting cultural heritages. Researchers and academicians will get insight and deeper understanding on the research trend and use the interdisciplinary of AI and cultural heritage for expanding collaboration.,This study will help to reveal the trend and evolution of AI and cultural heritage. The finding also will fill the knowledge gap on the research on AI and cultural heritage.,Some similar bibliometric studies have been conducted; however, there are still limited studies on contribution of AI to preserve cultural heritage in wider view. The value of this study is the cluster in which AI is used to preserve, curate, present and assess cultural heritages.},
  langid = {english},
  file = {F\:\\Zotero File\\storage\\BAFY9NRX\\Harisanty 等 - 2024 - Cultural heritage preservation in the digital age, harnessing artificial intelligence for the future.pdf;F\:\\Zotero File\\storage\\F3JWM7YZ\\html.html}
}
@inproceedings{carrieroArCoItalianCultural2019,
  title = {{{ArCo}}: {{The Italian Cultural Heritage Knowledge Graph}}},
  shorttitle = {{{ArCo}}},
  booktitle = {The {{Semantic Web}} -- {{ISWC}} 2019},
  author = {Carriero, Valentina Anita and Gangemi, Aldo and Mancinelli, Maria Letizia and Marinucci, Ludovica and Nuzzolese, Andrea Giovanni and Presutti, Valentina and Veninata, Chiara},
  editor = {Ghidini, Chiara and Hartig, Olaf and Maleshkova, Maria and Sv{\'a}tek, Vojt{\v e}ch and Cruz, Isabel and Hogan, Aidan and Song, Jie and Lefran{\c c}ois, Maxime and Gandon, Fabien},
  year = {2019},
  pages = {36--52},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-30796-7_3},
  abstract = {ArCo is the Italian Cultural Heritage knowledge graph, consisting of a network of seven vocabularies and 169 million triples about 820 thousand cultural entities. It is distributed jointly with a SPARQL endpoint, a software for converting catalogue records to RDF, and a rich suite of documentation material (testing, evaluation, how-to, examples, etc.). ArCo is based on the official General Catalogue of the Italian Ministry of Cultural Heritage and Activities (MiBAC) - and its associated encoding regulations - which collects and validates the catalogue records of (ideally) all Italian Cultural Heritage properties (excluding libraries and archives), contributed by CH administrators from all over Italy. We present its structure, design methods and tools, its growing community, and delineate its importance, quality, and impact.},
  isbn = {978-3-030-30796-7},
  langid = {english},
  file = {F:\Zotero File\storage\RBEPG5C5\Carriero 等 - 2019 - ArCo The Italian Cultural Heritage Knowledge Graph.pdf}
}
@article{douKnowledgeGraphBased2018,
  title = {Knowledge Graph Based on Domain Ontology and Natural Language Processing Technology for {{Chinese}} Intangible Cultural Heritage},
  author = {Dou, Jinhua and Qin, Jingyan and Jin, Zanxia and Li, Zhuang},
  year = {2018},
  month = oct,
  journal = {Journal of Visual Languages \& Computing},
  volume = {48},
  pages = {19--28},
  issn = {1045-926X},
  doi = {10.1016/j.jvlc.2018.06.005},
  urldate = {2025-05-12},
  abstract = {Intangible cultural heritage (ICH) is a precious historical and cultural resource of a country. Protection and inheritance of ICH is important to the sustainable development of national culture. There are many different intangible cultural heritage items in China. With the development of information technology, ICH database resources were built by government departments or public cultural services institutions, but most databases were widely dispersed. Certain traditional database systems are disadvantageous to storage, management and analysis of massive data. At the same time, a large quantity of data has been produced, accompanied by digital intangible cultural heritage development. The public is unable to grasp key knowledge quickly because of the massive and fragmented nature of the data. To solve these problems, we proposed the intangible cultural heritage knowledge graph to assist knowledge management and provide a service to the public. ICH domain ontology was defined with the help of intangible cultural heritage experts and knowledge engineers to regulate the concept, attribute and relationship of ICH knowledge. In this study, massive ICH data were obtained, and domain knowledge was extracted from ICH text data using the Natural Language Processing (NLP) technology. A knowledge base based on domain ontology and instances for Chinese intangible cultural heritage was constructed, and the knowledge graph was developed. The pattern and characteristics behind the intangible cultural heritage were presented based on the ICH knowledge graph. The knowledge graph for ICH could foster support for organization, management and protection of the intangible cultural heritage knowledge. The public can also obtain the ICH knowledge quickly and discover the linked knowledge. The knowledge graph is helpful for the protection and inheritance of intangible cultural heritage.},
  keywords = {Deep learning,Domain ontology,Intangible cultural heritage,Knowledge graph,Natural language processing,The 24 solar terms},
  file = {F\:\\Zotero File\\storage\\9Y6CCM3R\\Dou 等 - 2018 - Knowledge graph based on domain ontology and natural language processing technology for Chinese inta.pdf;F\:\\Zotero File\\storage\\LXDAWGRW\\S1045926X18300041.html}
}
@article{baiQwenTechnicalReport2023,
  title = {Qwen {{Technical Report}}},
  author = {Bai, Jinze and Bai, Shuai and Chu, Yunfei and Cui, Zeyu and Dang, Kai and Deng, Xiaodong and Fan, Yang and Ge, Wenbin and Han, Yu and Huang, Fei and Hui, Binyuan and Ji, Luo and Li, Mei and Lin, Junyang and Lin, Runji and Liu, Dayiheng and Liu, Gao and Lu, Chengqiang and Lu, Keming and Ma, Jianxin and Men, Rui and Ren, Xingzhang and Ren, Xuancheng and Tan, Chuanqi and Tan, Sinan and Tu, Jianhong and Wang, Peng and Wang, Shijie and Wang, Wei and Wu, Shengguang and Xu, Benfeng and Xu, Jin and Yang, An and Yang, Hao and Yang, Jian and Yang, Shusheng and Yao, Yang and Yu, Bowen and Yuan, Hongyi and Yuan, Zheng and Zhang, Jianwei and Zhang, Xingxuan and Zhang, Yichang and Zhang, Zhenru and Zhou, Chang and Zhou, Jingren and Zhou, Xiaohuan and Zhu, Tianhang},
  year = {2023},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2309.16609},
  urldate = {2025-05-12},
  abstract = {Large language models (LLMs) have revolutionized the field of artificial intelligence, enabling natural language processing tasks that were previously thought to be exclusive to humans. In this work, we introduce Qwen, the first installment of our large language model series. Qwen is a comprehensive language model series that encompasses distinct models with varying parameter counts. It includes Qwen, the base pretrained language models, and Qwen-Chat, the chat models finetuned with human alignment techniques. The base language models consistently demonstrate superior performance across a multitude of downstream tasks, and the chat models, particularly those trained using Reinforcement Learning from Human Feedback (RLHF), are highly competitive. The chat models possess advanced tool-use and planning capabilities for creating agent applications, showcasing impressive performance even when compared to bigger models on complex tasks like utilizing a code interpreter. Furthermore, we have developed coding-specialized models, Code-Qwen and Code-Qwen-Chat, as well as mathematics-focused models, Math-Qwen-Chat, which are built upon base language models. These models demonstrate significantly improved performance in comparison with open-source models, and slightly fall behind the proprietary models.},
  copyright = {Creative Commons Attribution 4.0 International},
  keywords = {Computation and Language (cs.CL),FOS: Computer and information sciences},
  file = {F:\Zotero File\storage\N5LL7KV7\Bai 等 - 2023 - Qwen Technical Report.pdf}
}
@article{gemmateamGemmaOpenModels2024,
  title = {Gemma: {{Open Models Based}} on {{Gemini Research}} and {{Technology}}},
  shorttitle = {Gemma},
  author = {{Gemma Team} and Mesnard, Thomas and Hardin, Cassidy and Dadashi, Robert and Bhupatiraju, Surya and Pathak, Shreya and Sifre, Laurent and Rivi{\`e}re, Morgane and Kale, Mihir Sanjay and Love, Juliette and Tafti, Pouya and Hussenot, L{\'e}onard and Sessa, Pier Giuseppe and Chowdhery, Aakanksha and Roberts, Adam and Barua, Aditya and Botev, Alex and {Castro-Ros}, Alex and Slone, Ambrose and H{\'e}liou, Am{\'e}lie and Tacchetti, Andrea and Bulanova, Anna and Paterson, Antonia and Tsai, Beth and Shahriari, Bobak and Lan, Charline Le and {Choquette-Choo}, Christopher A. and Crepy, Cl{\'e}ment and Cer, Daniel and Ippolito, Daphne and Reid, David and Buchatskaya, Elena and Ni, Eric and Noland, Eric and Yan, Geng and Tucker, George and Muraru, George-Christian and Rozhdestvenskiy, Grigory and Michalewski, Henryk and Tenney, Ian and Grishchenko, Ivan and Austin, Jacob and Keeling, James and Labanowski, Jane and Lespiau, Jean-Baptiste and Stanway, Jeff and Brennan, Jenny and Chen, Jeremy and Ferret, Johan and Chiu, Justin and {Mao-Jones}, Justin and Lee, Katherine and Yu, Kathy and Millican, Katie and Sjoesund, Lars Lowe and Lee, Lisa and Dixon, Lucas and Reid, Machel and Miku{\l}a, Maciej and Wirth, Mateo and Sharman, Michael and Chinaev, Nikolai and Thain, Nithum and Bachem, Olivier and Chang, Oscar and Wahltinez, Oscar and Bailey, Paige and Michel, Paul and Yotov, Petko and Chaabouni, Rahma and Comanescu, Ramona and Jana, Reena and Anil, Rohan and McIlroy, Ross and Liu, Ruibo and Mullins, Ryan and Smith, Samuel L and Borgeaud, Sebastian and Girgin, Sertan and Douglas, Sholto and Pandya, Shree and Shakeri, Siamak and De, Soham and Klimenko, Ted and Hennigan, Tom and Feinberg, Vlad and Stokowiec, Wojciech and Chen, Yu-hui and Ahmed, Zafarali and Gong, Zhitao and Warkentin, Tris and Peran, Ludovic and Giang, Minh and Farabet, Cl{\'e}ment and Vinyals, Oriol and Dean, Jeff and Kavukcuoglu, Koray and Hassabis, Demis and Ghahramani, Zoubin and Eck, Douglas and Barral, Joelle and Pereira, Fernando and Collins, Eli and Joulin, Armand and Fiedel, Noah and Senter, Evan and Andreev, Alek and Kenealy, Kathleen},
  year = {2024},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2403.08295},
  urldate = {2025-05-12},
  abstract = {This work introduces Gemma, a family of lightweight, state-of-the art open models built from the research and technology used to create Gemini models. Gemma models demonstrate strong performance across academic benchmarks for language understanding, reasoning, and safety. We release two sizes of models (2 billion and 7 billion parameters), and provide both pretrained and fine-tuned checkpoints. Gemma outperforms similarly sized open models on 11 out of 18 text-based tasks, and we present comprehensive evaluations of safety and responsibility aspects of the models, alongside a detailed description of model development. We believe the responsible release of LLMs is critical for improving the safety of frontier models, and for enabling the next wave of LLM innovations.},
  copyright = {Creative Commons Attribution 4.0 International},
  keywords = {Artificial Intelligence (cs.AI),Computation and Language (cs.CL),FOS: Computer and information sciences},
  file = {F:\Zotero File\storage\AZPX8QD4\Gemma Team 等 - 2024 - Gemma Open Models Based on Gemini Research and Technology.pdf}
}
@article{jiangMistral7B2023,
  title = {Mistral {{7B}}},
  author = {Jiang, Albert Q. and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and de las Casas, Diego and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and Lavaud, L{\'e}lio Renard and Lachaux, Marie-Anne and Stock, Pierre and Scao, Teven Le and Lavril, Thibaut and Wang, Thomas and Lacroix, Timoth{\'e}e and Sayed, William El},
  year = {2023},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2310.06825},
  urldate = {2025-05-12},
  abstract = {We introduce Mistral 7B v0.1, a 7-billion-parameter language model engineered for superior performance and efficiency. Mistral 7B outperforms Llama 2 13B across all evaluated benchmarks, and Llama 1 34B in reasoning, mathematics, and code generation. Our model leverages grouped-query attention (GQA) for faster inference, coupled with sliding window attention (SWA) to effectively handle sequences of arbitrary length with a reduced inference cost. We also provide a model fine-tuned to follow instructions, Mistral 7B -- Instruct, that surpasses the Llama 2 13B -- Chat model both on human and automated benchmarks. Our models are released under the Apache 2.0 license.},
  copyright = {Creative Commons Attribution 4.0 International},
  keywords = {Artificial Intelligence (cs.AI),Computation and Language (cs.CL),FOS: Computer and information sciences,Machine Learning (cs.LG)},
  file = {F:\Zotero File\storage\KHIGCQ7F\Jiang 等 - 2023 - Mistral 7B.pdf}
}
@article{touvronLlama2Open2023,
  title = {Llama 2: {{Open Foundation}} and {{Fine-Tuned Chat Models}}},
  shorttitle = {Llama 2},
  author = {Touvron, Hugo and Martin, Louis and Stone, Kevin R. and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Niko-lay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and Bikel, D. and Blecher, Lukas and Ferrer, Cris-tian Cant{\'o}n and Chen, Moya and Cucurull, Guillem and Esiobu, David and Fernandes, Jude and Fu, Jeremy and Fu, Wenyin and Fuller, Brian and Gao, Cynthia and Goswami, Vedanuj and Goyal, Naman and Hartshorn, A. and Hosseini, Saghar and Hou, Rui and Inan, Hakan and Kardas, Marcin and Kerkez, Viktor and Khabsa, Madian and Kloumann, Isabel M. and Korenev, A. and Koura, Punit Singh and Lachaux, M. and Lavril, Thibaut and Lee, Jenya and Liskovich, Diana and Lu, Yinghai and Mao, Yuning and Martinet, Xavier and Mihaylov, Todor and Mishra, Pushkar and Molybog, Igor and Nie, Yixin and Poulton, Andrew and Reizenstein, Jeremy and Rungta, Rashi and Saladi, Kalyan and Schelten, Alan and Silva, Ruan and Smith, Eric Michael and Subramanian, R. and Tan, Xia and Tang, Binh and Taylor, Ross and Williams, Adina and Kuan, Jian Xiang and Xu, Puxin and Yan, Zhengxu and Zarov, Iliyan and Zhang, Yuchen and Fan, Angela and Kambadur, M. and Narang, Sharan and Rodriguez, Aur'elien and Stojnic, Robert and Edunov, Sergey and Scialom, Thomas},
  year = {2023},
  month = jul,
  journal = {ArXiv},
  urldate = {2025-05-12},
  abstract = {In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters. Our fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our models outperform open-source chat models on most benchmarks we tested, and based on our human evaluations for helpfulness and safety, may be a suitable substitute for closed-source models. We provide a detailed description of our approach to fine-tuning and safety improvements of Llama 2-Chat in order to enable the community to build on our work and contribute to the responsible development of LLMs.},
  file = {F:\Zotero File\storage\5DUA7GGP\Touvron 等 - 2023 - Llama 2 Open Foundation and Fine-Tuned Chat Models.pdf}
}
@article{Jiang2021ResearchOM,
  title={Research on Medical Question Answering System Based on Knowledge Graph},
  author={Zhixue Jiang and Chengying Chi and Yunyun Zhan},
  journal={IEEE Access},
  year={2021},
  volume={9},
  pages={21094-21101},
  url={https://api.semanticscholar.org/CorpusID:231851657}
}